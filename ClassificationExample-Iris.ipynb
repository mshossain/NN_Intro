{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd78f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, \\\n",
    "TensorDataset, random_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ff31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce4d14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f54c29-84c0-414f-81c1-9791f67ef6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: 60% training, 20% validation, 20% testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b73c44c4-bf71-4869-a205-cdd1e989d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the training data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to the validation and test data\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efab654-02af-4879-918c-13cd32bd9453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12121831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84108446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc07c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)\n",
    "        self.fc2 = nn.Linear(16, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3074e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = IrisNet()\n",
    "\n",
    "# Define the loss function and optimizer with L2 regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001, \n",
    "                       weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5c1153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2766, Val Loss: 0.1926, Val Accuracy: 90.00%\n",
      "Epoch [2/20], Train Loss: 0.2656, Val Loss: 0.1867, Val Accuracy: 93.33%\n",
      "Epoch [3/20], Train Loss: 0.2821, Val Loss: 0.1816, Val Accuracy: 93.33%\n",
      "Epoch [4/20], Train Loss: 0.2661, Val Loss: 0.1760, Val Accuracy: 93.33%\n",
      "Epoch [5/20], Train Loss: 0.2617, Val Loss: 0.1728, Val Accuracy: 93.33%\n",
      "Epoch [6/20], Train Loss: 0.2532, Val Loss: 0.1647, Val Accuracy: 93.33%\n",
      "Epoch [7/20], Train Loss: 0.2428, Val Loss: 0.1588, Val Accuracy: 93.33%\n",
      "Epoch [8/20], Train Loss: 0.2310, Val Loss: 0.1529, Val Accuracy: 93.33%\n",
      "Epoch [9/20], Train Loss: 0.2308, Val Loss: 0.1474, Val Accuracy: 93.33%\n",
      "Epoch [10/20], Train Loss: 0.2430, Val Loss: 0.1426, Val Accuracy: 96.67%\n",
      "Epoch [11/20], Train Loss: 0.2228, Val Loss: 0.1395, Val Accuracy: 100.00%\n",
      "Epoch [12/20], Train Loss: 0.2071, Val Loss: 0.1343, Val Accuracy: 100.00%\n",
      "Epoch [13/20], Train Loss: 0.2074, Val Loss: 0.1285, Val Accuracy: 100.00%\n",
      "Epoch [14/20], Train Loss: 0.2038, Val Loss: 0.1234, Val Accuracy: 100.00%\n",
      "Epoch [15/20], Train Loss: 0.2041, Val Loss: 0.1196, Val Accuracy: 100.00%\n",
      "Epoch [16/20], Train Loss: 0.1883, Val Loss: 0.1152, Val Accuracy: 100.00%\n",
      "Epoch [17/20], Train Loss: 0.1895, Val Loss: 0.1113, Val Accuracy: 100.00%\n",
      "Epoch [18/20], Train Loss: 0.1833, Val Loss: 0.1073, Val Accuracy: 100.00%\n",
      "Epoch [19/20], Train Loss: 0.1803, Val Loss: 0.1030, Val Accuracy: 100.00%\n",
      "Epoch [20/20], Train Loss: 0.1780, Val Loss: 0.1004, Val Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # This loop iterates over the \n",
    "        # mini-batches of data provided \n",
    "        # by train_loader. Each mini-batch \n",
    "        # contains a small subset of the \n",
    "        # training data.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # The forward pass is performed here. \n",
    "        # The model processes the inputs and \n",
    "        # produces outputs (predictions).        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # The loss function (defined by criterion) \n",
    "        # calculates the difference between the \n",
    "        # model's predictions (outputs) and the\n",
    "        # true labels (labels). The result is\n",
    "        # the loss, which indicates how well\n",
    "        # the model's predictions match \n",
    "        # the actual values.\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            # A forward pass is performed on \n",
    "            # the validation data to generate predictions.\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # This line finds the class with the \n",
    "            # highest predicted probability for \n",
    "            # each sample. The torch.max function\n",
    "            # returns both the maximum value and \n",
    "            # the index of the maximum value along\n",
    "            # the specified dimension (in this case,\n",
    "            # the class index is returned).\n",
    "            # Second Parameter (1): This specifies \n",
    "            # the dimension along which to look for\n",
    "            # the maximum value. 0 refers to the \n",
    "            # batch dimension. 1 refers to the \n",
    "            # class dimension\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            # (predicted == labels).sum() is a tensor. \n",
    "            # dot item gives the scalar value.\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
    "          f'Val Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dab4634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Final Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e0d820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e280e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5375,  2.0272,  1.3696],\n",
      "        [-0.7054,  1.5739, -0.8543],\n",
      "        [-3.0890,  0.7420,  2.1909],\n",
      "        [-3.1081,  1.9119,  1.1253],\n",
      "        [ 3.7698, -1.1075, -2.6729],\n",
      "        [-3.9539,  0.2520,  3.5757],\n",
      "        [ 4.0012, -1.2146, -2.7226],\n",
      "        [ 3.6301, -1.1313, -2.5043],\n",
      "        [-3.7948,  0.1218,  3.5714],\n",
      "        [ 3.2924, -0.7268, -2.5243],\n",
      "        [-1.8728,  1.1073,  0.7724],\n",
      "        [-3.9521, -0.0632,  3.9356],\n",
      "        [-1.7092,  2.0768, -0.3600],\n",
      "        [ 4.4437, -1.5504, -2.8522]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ecd11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
